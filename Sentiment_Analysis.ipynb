{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072bc3fb-e5e4-430b-b0e7-b872c6370807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # For data manipulation and analysis\n",
    "import numpy as np # For numerical computations\n",
    "import matplotlib.pyplot as plt # For plotting and visualizing data\n",
    "import re # For working with regular expressions\n",
    "\n",
    "import nltk # Natural Language Toolkit for text preprocessing\n",
    "from nltk.corpus import stopwords # List of common stopwords (e.g., \"the\", \"is\", etc.)\n",
    "from nltk.stem.porter import PorterStemmer # For stemming words to their root form\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # To convert text to numerical features\n",
    "from sklearn.model_selection import train_test_split # To split dataset into training and testing\n",
    "from sklearn.ensemble import RandomForestClassifier # A machine learning model (ensemble method)\n",
    "from sklearn.metrics import accuracy_score # To evaluate model accuracy\n",
    "from sklearn.metrics import classification_report # To get precision, recall, F1-score etc.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # For confusion matrix and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2b047c-adbf-4df9-93f9-3a8ec2966d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti=pd.read_csv('train.csv') # To read the training dataset (CSV file) into a pandas DataFrame called 'senti'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b792e86-9cdf-4d5f-9d2f-449e890da0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti.head() # To display the first 5 rows of the dataset to inspect its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3dfb91-df79-4beb-9b80-5267fad2662a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti.shape # To output the shape (rows, columns) of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ed5e12-8776-4300-84b1-4348ce4e6139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\debar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords') # To download the list of English stopwords\n",
    "print(stopwords.words('english')) # To print the list to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f1dff6-9d03-4752-92be-88b9b10a74f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             1\n",
       "selected_text    1\n",
       "sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti.isnull().sum() # To count missing (NaN) values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de51a8b5-2f6a-4079-808e-1c0750b85704",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti=senti.dropna() # To remove rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efaff8c2-143c-4f90-a9a4-eb669dd4b017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID           0\n",
       "text             0\n",
       "selected_text    0\n",
       "sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti.isnull().sum() # To recheck to ensure no missing values remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71d3dfea-c3a2-44a8-aa4b-7e95a82f2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           selected_text sentiment\n",
      "0                    I`d have responded, if I were going   neutral\n",
      "1                                               Sooo SAD  negative\n",
      "2                                            bullying me  negative\n",
      "3                                         leave me alone  negative\n",
      "4                                          Sons of ****,  negative\n",
      "...                                                  ...       ...\n",
      "27476                                             d lost  negative\n",
      "27477                                      , don`t force  negative\n",
      "27478                          Yay good for both of you.  positive\n",
      "27479                         But it was worth it  ****.  positive\n",
      "27480  All this flirting going on - The ATG smiles. Y...   neutral\n",
      "\n",
      "[27480 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "x=senti.drop(columns=['text','textID'],axis=1) # To drop columns not used in modeling\n",
    "print(x) # To print resulting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7eb31a6-f1f4-43d5-a603-0bfc8af0c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter=PorterStemmer() # To create a PorterStemmer object for stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb19eae9-788f-4eff-9ccc-755dff54b6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english')) # To convert stopwords to a set for faster lookup\n",
    "\n",
    "def stemming(selected_text): # Function to clean and stem text\n",
    "    new_text=re.sub('[^a-zA-Z]',' ',selected_text) # To remove non-letter characters\n",
    "    new_text=new_text.lower() # To convert to lowercase\n",
    "    new_text=new_text.split() # To split into words\n",
    "    new_text=[porter.stem(word) for word in new_text if word not in stop_words] # To stem and remove stopwords\n",
    "    new_text=' '.join(new_text) # To rejoin words into a single string\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd7a3b8-84e4-46c0-994a-0e6b4d335583",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti['selected_text']=senti['selected_text'].apply(stemming) # To apply preprocessing to 'selected_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df682a5-46c2-4db1-bd7f-b9f2657a5ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                        respond go\n",
      "1                          sooo sad\n",
      "2                             bulli\n",
      "3                         leav alon\n",
      "4                               son\n",
      "                    ...            \n",
      "27476                          lost\n",
      "27477                          forc\n",
      "27478                      yay good\n",
      "27479                         worth\n",
      "27480    flirt go atg smile yay hug\n",
      "Name: selected_text, Length: 27480, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(senti['selected_text']) # To print the stemmed version of selected text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71ec53d9-cd2e-415b-8832-b130a41fd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=senti['selected_text'].values # Feature: processed text\n",
    "Y=senti['sentiment'].values # Label: sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cdabd09-32ec-432f-992b-65039be42c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['respond go' 'sooo sad' 'bulli' ... 'yay good' 'worth'\n",
      " 'flirt go atg smile yay hug']\n"
     ]
    }
   ],
   "source": [
    "print(X) # To print feature values                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "553e3940-076a-4d6a-aed6-2df93d7bf430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'negative' 'negative' ... 'positive' 'positive' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "print(Y) # To print target sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d51159e5-7bdd-4206-8d70-3a1cbc8a2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3) # 70% train, 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d2c56e-1843-47b5-8986-3f1dc355e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27480,) (19236,) (8244,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,X_train.shape,X_test.shape) # To display shapes of full, train, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dab2b001-74fb-437d-bb5b-0d05aa96c137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sad' 'jam session room see star trek'\n",
      " 'chillen csla wait start watchin pacquiao rerun' ... 'cool movi'\n",
      " 'wow beauti pictur' 'sorri']\n"
     ]
    }
   ],
   "source": [
    "print(X_train) # To print training feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df075b9e-ac37-4e5f-a748-6b0df996cbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['well inspir day room design today schedul head bed' 'forgot fan haha'\n",
      " 'love' ... 'snugglin tila' 'fair' 'toy stori pwn']\n"
     ]
    }
   ],
   "source": [
    "print(X_test) # To print test feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e9777d1-b62d-40a2-813e-5e79abed4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=TfidfVectorizer() # To create TF-IDF vectorizer object\n",
    "vector.fit(X) # To learn vocabulary from all data\n",
    "X_train=vector.transform(X_train) # To transform training data into vectors\n",
    "X_test=vector.transform(X_test) # To transform test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33b04c7b-a077-4ebf-b89f-71c861a8695e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9807)\t1.0\n",
      "  (1, 5901)\t0.4989923758561556\n",
      "  (1, 9692)\t0.3896632185942222\n",
      "  (1, 10018)\t0.2795672226059586\n",
      "  (1, 10084)\t0.467177049116599\n",
      "  (1, 10838)\t0.36695978180436206\n",
      "  (1, 11824)\t0.40999692227309764\n",
      "  (2, 2016)\t0.4175637075378642\n",
      "  (2, 2630)\t0.446992727171066\n",
      "  (2, 8361)\t0.446992727171066\n",
      "  (2, 9513)\t0.4175637075378642\n",
      "  (2, 10851)\t0.25211223416420464\n",
      "  (2, 12488)\t0.23525808644616047\n",
      "  (2, 12552)\t0.3643750240524671\n",
      "  (3, 2251)\t1.0\n",
      "  (4, 1074)\t0.46761866814727726\n",
      "  (4, 2190)\t0.4115776353025025\n",
      "  (4, 2333)\t0.3438696333580786\n",
      "  (4, 2806)\t0.3911188682532427\n",
      "  (4, 4320)\t0.39109537406012335\n",
      "  (4, 9612)\t0.27006402727742523\n",
      "  (4, 10363)\t0.3388600994937592\n",
      "  (5, 3456)\t0.4740366023057642\n",
      "  (5, 7887)\t0.5797523660525763\n",
      "  (5, 8641)\t0.5504959243531207\n",
      "  :\t:\n",
      "  (19228, 8471)\t0.35367949348731975\n",
      "  (19228, 10341)\t0.3173396122058412\n",
      "  (19228, 12233)\t0.29174134938499474\n",
      "  (19228, 12616)\t0.251859752871833\n",
      "  (19229, 745)\t0.35749826273882623\n",
      "  (19229, 1254)\t0.4299188390292576\n",
      "  (19229, 3289)\t0.7319458436960089\n",
      "  (19229, 4629)\t0.22513756861110992\n",
      "  (19229, 11705)\t0.31769976563175467\n",
      "  (19230, 2806)\t0.2997783015168608\n",
      "  (19230, 4061)\t0.4592708551787471\n",
      "  (19230, 4520)\t0.31352160349340846\n",
      "  (19230, 6027)\t0.484436011386486\n",
      "  (19230, 7819)\t0.38685754921920984\n",
      "  (19230, 9319)\t0.46537129601000266\n",
      "  (19231, 5774)\t0.7786193253623789\n",
      "  (19231, 12066)\t0.4752030857344474\n",
      "  (19231, 12488)\t0.40979747861680815\n",
      "  (19232, 9807)\t1.0\n",
      "  (19233, 2427)\t0.6919127431897184\n",
      "  (19233, 7545)\t0.7219811325870494\n",
      "  (19234, 1003)\t0.5677698515920861\n",
      "  (19234, 8663)\t0.6067945474916354\n",
      "  (19234, 12943)\t0.5562713121827528\n",
      "  (19235, 10635)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train) # To print sparse matrix of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "798bfb01-054f-4d66-9e99-2ae364d66a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1022)\t0.29797611840881305\n",
      "  (0, 2806)\t0.20514415568529845\n",
      "  (0, 2970)\t0.4102636656845808\n",
      "  (0, 5121)\t0.31356516312264326\n",
      "  (0, 5744)\t0.4183696126748751\n",
      "  (0, 9692)\t0.35147596046331475\n",
      "  (0, 9942)\t0.4213933833351253\n",
      "  (0, 11662)\t0.24265842216102643\n",
      "  (0, 12644)\t0.25973591277192803\n",
      "  (1, 3882)\t0.6123894706952528\n",
      "  (1, 4197)\t0.6243181613619168\n",
      "  (1, 4938)\t0.4849803806086012\n",
      "  (2, 6821)\t1.0\n",
      "  (3, 8094)\t0.6642153459740069\n",
      "  (3, 9205)\t0.7475412859318409\n",
      "  (4, 4567)\t0.4444277948424851\n",
      "  (4, 5121)\t0.4489076297981768\n",
      "  (4, 5385)\t0.35030552051569336\n",
      "  (4, 8120)\t0.44299486930567766\n",
      "  (4, 10631)\t0.5310437488055986\n",
      "  (5, 4330)\t1.0\n",
      "  (6, 7364)\t1.0\n",
      "  (7, 4694)\t1.0\n",
      "  (8, 4126)\t0.4492213413546151\n",
      "  (8, 4715)\t0.2748919178126278\n",
      "  :\t:\n",
      "  (8235, 1231)\t0.33665007682526954\n",
      "  (8235, 1603)\t0.32597487839152556\n",
      "  (8235, 1956)\t0.3085967520334949\n",
      "  (8235, 2276)\t0.26480362109241895\n",
      "  (8235, 2667)\t0.39528930573583115\n",
      "  (8235, 5455)\t0.2523460665315504\n",
      "  (8235, 6615)\t0.21234062073774698\n",
      "  (8235, 8894)\t0.3223009121981395\n",
      "  (8235, 12340)\t0.49614070744072686\n",
      "  (8236, 3576)\t0.7435786963971943\n",
      "  (8236, 7817)\t0.6686484294935936\n",
      "  (8237, 3936)\t1.0\n",
      "  (8238, 2150)\t0.35920966752404154\n",
      "  (8238, 2408)\t0.4376643560687711\n",
      "  (8238, 3316)\t0.5412506972558156\n",
      "  (8238, 8747)\t0.3058000844086909\n",
      "  (8238, 9696)\t0.5412506972558156\n",
      "  (8239, 1351)\t1.0\n",
      "  (8240, 5465)\t1.0\n",
      "  (8241, 10531)\t0.7307530690162836\n",
      "  (8241, 11598)\t0.6826418915678136\n",
      "  (8242, 3861)\t1.0\n",
      "  (8243, 9146)\t0.6766580472150004\n",
      "  (8243, 10941)\t0.49269981019308395\n",
      "  (8243, 11769)\t0.5471570013943723\n"
     ]
    }
   ],
   "source": [
    "print(X_test) # To print sparse matrix of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07efa8da-fee8-442e-bdab-2b10b47734bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RandomForestClassifier(n_estimators=100)# To initialize with 100 decision trees\n",
    "model.fit(X_train, Y_train)# To train model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848a37e-75a9-4d3e-8bac-12a49200a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pred=model.predict(X_train) # To use the trained model to predict labels for the training data\n",
    "train_accuracy=accuracy_score(X_train_pred,Y_train) # To calculate training accuracy by comparing predicted and actual labels\n",
    "print('Accuracy of training data: ',train_accuracy) # To print the computed accuracy score to the console\n",
    "plt.figure(figsize=(4,4)) # To create a new figure for the plot with width and height=4 inches\n",
    "plt.bar(['Training Accuracy'],[train_accuracy],color='orange') # To draw a bar chart with a single bar for training accuracy\n",
    "plt.ylim(0,1) # To set the y-axis limits from 0 to 1 since accuracy is a ratio\n",
    "plt.ylabel(\"Accuracy Score\") # To label the y-axis\n",
    "plt.title(\"Training Accuracy\") # To add a title to the bar chart\n",
    "plt.text(0,train_accuracy-0.05,f\"{train_accuracy:.2f}\",fontsize=12,color='white',ha='center') # To add a text label above the bar to show the exact accuracy value with 2 decimal places\n",
    "plt.show() # To display the final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd92450-d168-4e95-97fc-22edad8d6a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred=model.predict(X_test) # To use the trained model to predict sentiment labels for the test data\n",
    "test_accuracy=accuracy_score(X_test_pred,Y_test) # To calculate test accuracy by comparing predictions to true labels\n",
    "print('Accuracy of testing data: ',test_accuracy) # To rint the test accuracy to the console\n",
    "plt.figure(figsize=(4, 4)) # To create a new figure for plotting with 4x4 inch dimensions\n",
    "plt.bar(['Test Accuracy'],[test_accuracy],color='blue')# To create a bar chart showing test accuracy in blue\n",
    "plt.ylim(0,1) # To set the vertical axis (y-axis) limits between 0 and 1\n",
    "plt.ylabel(\"Accuracy Score\") # To label the y-axis as \"Accuracy Score\"\n",
    "plt.title(\"Test Accuracy\") # To add a title to the chart\n",
    "plt.text(0,test_accuracy-0.05,f\"{test_accuracy:.2f}\",fontsize=12,color='white',ha='center') # To add a text label above the bar to show the exact accuracy value with 2 decimal places\n",
    "plt.show() # To render and display the final plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6eeb51-768c-4d95-865a-f041c46643b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test) # To use the trained model to predict sentiment labels on the test dataset\n",
    "print(\"Classification Report:\\n\") # To print a heading to indicate the following output is a classification report\n",
    "print(classification_report(Y_test,Y_pred)) # To print precision, recall, F1-score, and support for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c0b57-954f-40c8-8657-1ae57d255dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4)) # To create a new plot with width 6 inches and height 4 inches\n",
    "plt.bar(['Train Accuracy','Test Accuracy'],[train_accuracy, test_accuracy],color=['orange', 'blue']) # To plots two bars:One for training accuracy(train_accuracy) in orange and One for test accuracy(test_accuracy) in blue\n",
    "plt.ylim(0,1) # To set the vertical axis (y-axis) to range from 0 to 1(0% to 100% accuracy)\n",
    "plt.ylabel(\"Accuracy Score\") # To add a label to the y-axis\n",
    "plt.title(\"Train vs Test Accuracy Comparison\") # To add a descriptive title to the chart\n",
    "plt.text(0, train_accuracy - 0.05, f\"{train_accuracy:.2f}\", ha='center', color='white') # To add a label on(or slightly below)the training accuracy bar with the exact value \n",
    "plt.text(1, test_accuracy - 0.05, f\"{test_accuracy:.2f}\", ha='center', color='white') # To add a label on(or slightly below)the training accuracy bar with the exact value\n",
    "plt.show() # To render and display the final chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd8210-59be-49b4-88f4-5c8d34073376",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels,counts=np.unique(Y_pred,return_counts=True) # To count how many times each label appears and requency of each class in predictions\n",
    "plt.figure(figsize=(5,5)) # To create a new square figure for the pie chart (5x5 inches)\n",
    "plt.pie(counts,labels=labels,autopct='%1.1f%%',startangle=140,colors=['skyblue','lightcoral','red']) # To draw a pie chart depicting distribution of predicted labels\n",
    "plt.title(\"Distribution of Predicted Labels\") # To add a title to explain the pie chart\n",
    "plt.axis('equal') # To ensure the pie chart is drawn as a circle (equal aspect ratio)\n",
    "plt.show() # To render and display the pie chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4972ab-1bb4-4bb2-a0d6-e6d63cd817b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(Y_test, Y_pred) # To compute the confusion matrix\n",
    "disp=ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_) # To create a ConfusionMatrixDisplay object for plotting.\n",
    "disp.plot(cmap=plt.cm.Blues) # To render the confusion matrix as a heatmap using a blue color gradient \n",
    "plt.title(\"Confusion Matrix\") # To add a title above the plot\n",
    "plt.show() # To display the final confusion matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad4205-aad1-4a44-91eb-c495384774d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict sentiment for custom user input\n",
    "def predict_sentiment(user_input):\n",
    "    # Preprocess the input like the training data\n",
    "    processed_input=stemming(user_input)\n",
    "    vectorized_input=vector.transform([processed_input])\n",
    "    prediction=model.predict(vectorized_input)[0]\n",
    "    # Return the predicted sentiment label\n",
    "    return f\"{prediction.capitalize()}üòä\" if prediction=='positive' else(\n",
    "           f\"{prediction.capitalize()}üòê\" if prediction=='neutral' else\n",
    "           f\"{prediction.capitalize()}üòû\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4965b4-99e8-4470-992b-ed4906964d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To ask for user input\n",
    "print(\"\\nSentiment Prediction(Type'exit'to quit)\\n\")\n",
    "while True:\n",
    "    try:\n",
    "        user_input=input(\"Enter a sentence: \") # To take input from user\n",
    "        if user_input.lower()=='exit': # To exit loop if 'exit'\n",
    "            print(\"Goodbye!üëã\")\n",
    "            break\n",
    "        result=predict_sentiment(user_input) # To predict sentiment\n",
    "        print(\"Predicted Sentiment:\",result)\n",
    "        print(\"-\"*40)\n",
    "    except Exception as e:\n",
    "        print(\"Something went wrong:\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4b30fa-c23b-4ee7-8511-4980f4cc729b",
   "metadata": {},
   "source": [
    "DEBARATI_GHOSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39dde9f-845e-4e8d-bbb0-303a439a8710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
